{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install convokit\n",
    "# !pip install wordcloud\n",
    "# !pip install --upgrade Pillow\n",
    "# !pip install --upgrade pip \n",
    "# !pip install --upgrade Pillow\n",
    "# !python -m pip install spacy-llm\n",
    "# !python -m pip install spacy\n",
    "# !pip install -U pip setuptools wheel\n",
    "# !pip install -U spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "# !pip install -U spacy[cuda113]\n",
    "# !pip install -U spacy[cuda90]\n",
    "# !pip install spacy_transformers\n",
    "# !pip install accelerate\n",
    "# !python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque 1: Librerías básicas de manipulación y procesamiento de datos\n",
    "import re, os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "# Bloque 2: Librerías para procesamiento de texto y visualización\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Bloque 3: Librerías para preprocesamiento y evaluación de modelos de machine learning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Bloque 4: Procesamiento de texto con spaCy\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Bloque 5: Librerías de visualización gráfica\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Bloque 6: Configuración de TensorFlow y Keras para aprendizaje profundo\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, GRU, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Bloque 7: Librerías para manejo de modelos de lenguaje y transferencia de conocimiento\n",
    "import tensorflow_hub as hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoModelForTokenClassification, pipeline\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Bloque 8: Librerías para evaluación de modelos y métricas\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, recall_score, precision_score, ConfusionMatrixDisplay, fbeta_score, f1_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Bloque 9: Librerías para procesamiento de texto con Transformers y Hugging Face\n",
    "import plotly.express as px\n",
    "import spacy\n",
    "\n",
    "\n",
    "# Bloque 10: Librerías para análisis de similitud y extracción de características de texto\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(dataframe, columns=['messages', 'sender_labels', 'receiver_labels']):\n",
    "    \"\"\"\n",
    "    Elimina las filas con valores NaN en columnas especificadas.\n",
    "\n",
    "    Parámetros:\n",
    "    - dataframe: pd.DataFrame\n",
    "        El DataFrame a procesar.\n",
    "    - columns: list\n",
    "        Lista de columnas en las que buscar valores NaN.\n",
    "\n",
    "    Retorna:\n",
    "    - pd.DataFrame\n",
    "        DataFrame con las filas que contienen valores NaN eliminadas.\n",
    "    \"\"\"\n",
    "    return dataframe.dropna(subset=columns)\n",
    "\n",
    "\n",
    "def remove_tags(string, remove_special_chars=False, remove_stopwords=False, remove_newlines=False):\n",
    "    \"\"\"\n",
    "    Elimina etiquetas y contenido no deseado de una cadena de texto, como etiquetas HTML, nombres de usuario de Twitter, hashtags, números y URLs.\n",
    "\n",
    "    Parámetros:\n",
    "    - string: str\n",
    "        Cadena de texto a procesar.\n",
    "    - remove_special_chars: bool\n",
    "        Indica si se deben eliminar caracteres no alfanuméricos.\n",
    "    - remove_stopwords: bool\n",
    "        Indica si se deben eliminar palabras comunes (stopwords).\n",
    "    - remove_newlines: bool\n",
    "        Indica si se deben eliminar caracteres de nueva línea.\n",
    "\n",
    "    Retorna:\n",
    "    - str\n",
    "        Cadena de texto procesada y limpia.\n",
    "    \"\"\"\n",
    "    result = re.sub(r'<.*?>', '', string)  # Elimina etiquetas HTML\n",
    "    result = re.sub('@[\\w]+', '', result)  # Elimina nombres de usuario de Twitter\n",
    "    result = re.sub('#[\\w]+', '', result)  # Elimina hashtags\n",
    "    result = re.sub(\"\\d+\", \" \", result)  # Elimina números\n",
    "    result = re.sub(r'http\\S+', '', result)  # Elimina URLs\n",
    "\n",
    "    if remove_special_chars:\n",
    "        result = re.sub(r'[^\\w\\s]', ' ', result)  # Elimina caracteres no alfanuméricos\n",
    "\n",
    "    if remove_newlines:\n",
    "        result = re.sub(r'\\n\\n', ' ', result)  # Elimina caracteres de nueva línea\n",
    "        result = ' '.join(result.split())  # Divide y une para eliminar espacios adicionales\n",
    "\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        result = ' '.join([w for w in result.split() if w.lower() not in stop_words])\n",
    "\n",
    "    # Elimina palabras de longitud 1\n",
    "    result = ' '.join([word for word in result.split() if len(word) > 1])\n",
    "\n",
    "    result = result.lower()\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_class_weight(train_y):\n",
    "    \"\"\"\n",
    "    Calcula el peso de las clases dado un conjunto de datos de entrenamiento desbalanceado.\n",
    "    Generalmente utilizado en modelos de redes neuronales para ajustar la función de pérdida (función de pérdida ponderada),\n",
    "    dando más peso a las clases raras.\n",
    "\n",
    "    Parámetros:\n",
    "    - train_y: array\n",
    "        Etiquetas del conjunto de datos de entrenamiento.\n",
    "\n",
    "    Retorna:\n",
    "    - dict\n",
    "        Diccionario que asigna el peso a cada clase.\n",
    "    \"\"\"\n",
    "    import sklearn.utils.class_weight as scikit_class_weight\n",
    "\n",
    "    class_list = list(set(train_y))\n",
    "    class_weight_value = scikit_class_weight.compute_class_weight(class_weight='balanced', classes=class_list, y=train_y)\n",
    "    class_weight = dict()\n",
    "\n",
    "    # Inicializa todas las clases en el diccionario con peso 1\n",
    "    curr_max = int(np.max(class_list))\n",
    "    for i in range(curr_max):\n",
    "        class_weight[i] = 1\n",
    "\n",
    "    # Construye el diccionario utilizando el peso obtenido de la función de scikit\n",
    "    for i in range(len(class_list)):\n",
    "        class_weight[class_list[i]] = class_weight_value[i]\n",
    "\n",
    "    return class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar y Preparar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Cargar datos de entrenamiento desde el archivo 'train.jsonl'\n",
    "data_list = []\n",
    "messages = []\n",
    "with open('NLP_Diplomacy/train.jsonl', 'r') as archivo:\n",
    "    for line in archivo:\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            data_list.append(data)\n",
    "            messages.extend(data['messages'])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "# Paso 2: Cargar datos de validación desde el archivo 'validation.jsonl'\n",
    "validation_list = []\n",
    "messages = []\n",
    "with open('NLP_Diplomacy/validation.jsonl', 'r') as archivo:\n",
    "    for line in archivo:\n",
    "        try:\n",
    "            validation = json.loads(line)\n",
    "            validation_list.append(validation)\n",
    "            messages.extend(validation['messages'])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "# Paso 3: Cargar datos de prueba desde el archivo 'test.jsonl'\n",
    "test_list = []\n",
    "messages = []\n",
    "with open('NLP_Diplomacy/test.jsonl', 'r') as archivo:\n",
    "    for line in archivo:\n",
    "        try:\n",
    "            test = json.loads(line)\n",
    "            test_list.append(validation)\n",
    "            messages.extend(validation['messages'])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "# Paso 4: Crear DataFrames a partir de las listas de datos\n",
    "df = pd.DataFrame(data_list)\n",
    "df_val = pd.DataFrame(validation_list)\n",
    "df_test = pd.DataFrame(test_list)\n",
    "\n",
    "# Paso 5: \"Explotar\" las columnas de listas en filas individuales\n",
    "df_explode = df.explode(['messages', 'sender_labels', 'receiver_labels', 'speakers', 'receivers', 'absolute_message_index', 'relative_message_index', 'seasons', 'years', 'game_score', 'game_score_delta'], ignore_index=True)\n",
    "df_val = df_val.explode(['messages', 'sender_labels', 'receiver_labels', 'speakers', 'receivers', 'absolute_message_index', 'relative_message_index', 'seasons', 'years', 'game_score', 'game_score_delta'], ignore_index=True)\n",
    "df_test = df_test.explode(['messages', 'sender_labels', 'receiver_labels', 'speakers', 'receivers', 'absolute_message_index', 'relative_message_index', 'seasons', 'years', 'game_score', 'game_score_delta'], ignore_index=True)\n",
    "\n",
    "# Paso 6: Limpiar filas con valores NaN\n",
    "df_explode_cleaned = remove_nan_rows(df_explode)\n",
    "df_val_cleaned = remove_nan_rows(df_val)\n",
    "df_test_cleaned = remove_nan_rows(df_test)\n",
    "\n",
    "# Paso 7: Convertir la columna 'messages' a tipo de dato string y limpiar el texto\n",
    "df_explode_cleaned['messages'] = df_explode_cleaned['messages'].astype(str)\n",
    "df_explode_cleaned.loc[:, 'messages_clean'] = df_explode_cleaned['messages'].apply(lambda cw: remove_tags(cw, remove_special_chars=True, remove_stopwords=True, remove_newlines=True))\n",
    "\n",
    "df_val_cleaned['messages'] = df_val_cleaned['messages'].astype(str)\n",
    "df_val_cleaned.loc[:, 'messages_clean'] = df_val_cleaned['messages'].apply(lambda cw: remove_tags(cw, remove_special_chars=True, remove_stopwords=True, remove_newlines=True))\n",
    "\n",
    "df_test_cleaned['messages'] = df_test_cleaned['messages'].astype(str)\n",
    "df_test_cleaned.loc[:, 'messages_clean'] = df_test_cleaned['messages'].apply(lambda cw: remove_tags(cw, remove_special_chars=True, remove_stopwords=True, remove_newlines=True))\n",
    "\n",
    "# Paso 8: Limpiar filas con valores NaN después de la limpieza adicional\n",
    "df_explode_cleaned = remove_nan_rows(df_explode_cleaned)\n",
    "df_val_cleaned = remove_nan_rows(df_val_cleaned)\n",
    "df_test_cleaned = remove_nan_rows(df_test_cleaned)\n",
    "\n",
    "# Paso 9: Calcular la longitud del texto en cada fila\n",
    "df_explode_cleaned['caracteres_texto'] = df_explode_cleaned['messages_clean'].apply(lambda row: len(str(row)) if not pd.isna(row) else np.nan)\n",
    "\n",
    "# Paso 10: Filtrar DataFrame con condiciones específicas\n",
    "filtered_dfb = df_explode_cleaned[(df_explode_cleaned['sender_labels'] == False) & (df_explode_cleaned['receiver_labels'] == True) | \n",
    "                                  (df_explode_cleaned['sender_labels'] == True) & (df_explode_cleaned['receiver_labels'] == False)| \n",
    "                                  (df_explode_cleaned['sender_labels'] == False) & (df_explode_cleaned['receiver_labels'] == False)| \n",
    "                                  (df_explode_cleaned['sender_labels'] == True) & (df_explode_cleaned['receiver_labels'] == True) & (df_explode_cleaned['caracteres_texto'] <= 20)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando Datos para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 11: Obtener mensajes de entrenamiento y etiquetas asociadas\n",
    "train_messages = filtered_dfb['messages_clean'].values\n",
    "train_labels = filtered_dfb[\"sender_labels\"].values\n",
    "\n",
    "# Paso 12: Obtener mensajes de validación y etiquetas asociadas\n",
    "val_messages = df_val_cleaned['messages_clean'].values\n",
    "val_labels = df_val_cleaned[\"sender_labels\"].values\n",
    "\n",
    "# Paso 13: Obtener mensajes de prueba y etiquetas asociadas\n",
    "test_messages = df_test_cleaned['messages_clean'].values\n",
    "test_labels = df_test_cleaned[\"sender_labels\"].values\n",
    "\n",
    "# Paso 14: Inicializar y ajustar el codificador de etiquetas\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Paso 15: Codificar las etiquetas para entrenamiento, validación y prueba\n",
    "train_encoded_labels = encoder.fit_transform(train_labels)\n",
    "val_encoded_labels = encoder.fit_transform(val_labels)\n",
    "test_encoded_labels = encoder.fit_transform(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización y creación del diccionario de palabras (Tokens) restringiendo la cantidad de palabras\n",
    "vocab_size = 1000 ## -> Parámetro a calibrar\n",
    "oov_tok = ''\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_messages)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding\n",
    "max_length = 30 ## -> Parámetro a calibrar\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "# Se convierte la secuencia de train\n",
    "train_sequences = tokenizer.texts_to_sequences(train_messages)\n",
    "train_padded = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "# Se convierte la secuencia de val\n",
    "val_sequences = tokenizer.texts_to_sequences(val_messages)\n",
    "val_padded = tf.keras.preprocessing.sequence.pad_sequences(val_sequences, padding='post', maxlen=max_length)\n",
    "# Se convierte la secuencia de test\n",
    "test_sequences = tokenizer.texts_to_sequences(test_messages)\n",
    "test_padded = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición y Documentación del Modelo GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GRU_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 32)            32000     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               62208     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,337\n",
      "Trainable params: 94,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "\n",
    "gru_model = Sequential(name=\"GRU_Model\")\n",
    "gru_model.add(Embedding(vocab_size,embedding_dim,input_length=max_length))\n",
    "gru_model.add(GRU(128))\n",
    "gru_model.add(Dense(1, activation='sigmoid'))\n",
    " \n",
    "print(gru_model.summary())\n",
    "\n",
    "optimizador = tf.keras.optimizers.Adam(learning_rate=0.0005,\n",
    "                                       beta_1=0.9,\n",
    "                                       beta_2=0.999,\n",
    "                                       epsilon=1e-07)\n",
    "gru_model.compile(loss='binary_crossentropy',optimizer=\"nadam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "126/126 [==============================] - 4s 18ms/step - loss: 0.3578 - accuracy: 0.8644 - val_loss: 0.7396 - val_accuracy: 0.3001\n",
      "Epoch 2/7\n",
      "126/126 [==============================] - 2s 17ms/step - loss: 0.2637 - accuracy: 0.8814 - val_loss: 0.5405 - val_accuracy: 0.5148\n",
      "Epoch 3/7\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.2479 - accuracy: 0.8939 - val_loss: 0.4753 - val_accuracy: 0.8969\n",
      "Epoch 4/7\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.2331 - accuracy: 0.9026 - val_loss: 0.4891 - val_accuracy: 0.5593\n",
      "Epoch 5/7\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.2259 - accuracy: 0.9096 - val_loss: 0.5869 - val_accuracy: 0.5191\n",
      "Epoch 6/7\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.2179 - accuracy: 0.9131 - val_loss: 0.4456 - val_accuracy: 0.6179\n",
      "Epoch 7/7\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 0.2062 - accuracy: 0.9236 - val_loss: 0.3509 - val_accuracy: 0.7620\n",
      "\n",
      "GRU model Score--->  [0.3081206679344177, 0.8666666746139526]\n"
     ]
    }
   ],
   "source": [
    "history = gru_model.fit(train_padded,\n",
    "                        train_encoded_labels,batch_size=32,\n",
    "                        epochs=7,\n",
    "                        verbose=1,\n",
    "                        validation_data=(val_padded, val_encoded_labels))\n",
    " \n",
    "# Se imprime el valor de la función de pérdida y accuracy sobre el set de Test\n",
    "print()\n",
    "print(\"GRU model Score---> \", gru_model.evaluate(test_padded, test_encoded_labels, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicación Conceptual:\n",
    "Este modelo utiliza una arquitectura de Red Neuronal Recurrente (RNN) tipo GRU (Gated Recurrent Unit) para el procesamiento de secuencias de texto. La capa de Embedding convierte las palabras en vectores de números reales. La capa GRU ayuda al modelo a aprender patrones secuenciales en los datos de entrada. Finalmente, la capa Dense con función de activación sigmoidal realiza la clasificación binaria. El modelo se compila con una función de pérdida de entropía cruzada binaria y se entrena con datos de entrenamiento, validación y se evalúa en un conjunto de prueba. Los resultados incluyen la precisión y la función de pérdida en el conjunto de prueba.\n",
    "\n",
    "Descripción:\n",
    "\n",
    "Este modelo utiliza una capa de Embedding para convertir las palabras en vectores de longitud fija.\n",
    "La capa GRU (Gated Recurrent Unit) es una red neuronal recurrente que ayuda a modelar dependencias a largo plazo en secuencias de datos.\n",
    "La capa Dense con activación sigmoide produce la salida binaria, indicando la probabilidad de que la etiqueta sea 1 (True).\n",
    "\n",
    "Resultados:\n",
    "\n",
    "El modelo muestra una precisión (accuracy) de alrededor del 92.36% en el conjunto de entrenamiento y del 76.20% en el conjunto de validación después de 7 épocas.\n",
    "La evaluación en el conjunto de prueba indica una pérdida de aproximadamente 0.3081 y una precisión del 86.67%.\n",
    "Análisis:\n",
    "\n",
    "El modelo parece tener un buen rendimiento en el conjunto de entrenamiento, pero hay una diferencia significativa en la precisión entre el conjunto de entrenamiento y el conjunto de validación, lo que sugiere cierto grado de sobreajuste.\n",
    "Sería recomendable ajustar la arquitectura del modelo o considerar técnicas de regularización para mejorar la generalización en el conjunto de validación y prueba.\n",
    "Se podría probar con diferentes valores de embedding_dim y max_length para encontrar la configuración óptima del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con Transfer Learning (Universal Sentence Encoder):\n",
    "\n",
    "Descripción:\n",
    "\n",
    "Este modelo utiliza transfer learning con el Universal Sentence Encoder (USE) como capa inicial.\n",
    "Se utiliza el paquete tensorflow_hub para cargar el modelo USE directamente desde TensorFlow Hub.\n",
    "La capa USE se ajusta para ser trainable (trainable=True) en este caso.\n",
    "Se agrega una capa de Reshape para ajustar la forma de entrada al modelo.\n",
    "Se añade una capa GRU (Gated Recurrent Unit) con 128 unidades para procesar las secuencias.\n",
    "La capa Dense con activación sigmoide produce la salida con dos clases (binaria).\n",
    "Transfer Learning:\n",
    "\n",
    "El Universal Sentence Encoder es un modelo de procesamiento de lenguaje natural preentrenado que captura información semántica de las oraciones.\n",
    "En este caso, la capa USE se utiliza como un extractor de características y se conecta a las capas adicionales del modelo para la tarea específica de clasificación binaria.\n",
    "Al ajustar trainable=True, se permite que las capas del USE se adapten a los datos específicos de la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_one_hot = tf.keras.utils.to_categorical(train_labels, num_classes=2)\n",
    "test_labels_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes=2)\n",
    "val_labels_one_hot = tf.keras.utils.to_categorical(val_labels, num_classes=2)\n",
    "train_labels_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "126/126 [==============================] - 180s 1s/step - loss: 0.3079 - accuracy: 0.8786 - val_loss: 0.3823 - val_accuracy: 0.8220\n",
      "Epoch 2/7\n",
      "126/126 [==============================] - 179s 1s/step - loss: 0.2374 - accuracy: 0.9013 - val_loss: 0.2915 - val_accuracy: 0.9174\n",
      "Epoch 3/7\n",
      "126/126 [==============================] - 202s 2s/step - loss: 0.1642 - accuracy: 0.9463 - val_loss: 0.5463 - val_accuracy: 0.7196\n",
      "Epoch 4/7\n",
      "126/126 [==============================] - 185s 1s/step - loss: 0.0859 - accuracy: 0.9773 - val_loss: 1.1227 - val_accuracy: 0.6109\n",
      "Epoch 5/7\n",
      "126/126 [==============================] - 174s 1s/step - loss: 0.0512 - accuracy: 0.9865 - val_loss: 1.0344 - val_accuracy: 0.6773\n",
      "Epoch 6/7\n",
      "126/126 [==============================] - 191s 2s/step - loss: 0.0402 - accuracy: 0.9890 - val_loss: 0.8461 - val_accuracy: 0.7535\n",
      "Epoch 7/7\n",
      "126/126 [==============================] - 181s 1s/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 1.3460 - val_accuracy: 0.6582\n",
      "\n",
      "Model Score:  [0.41896864771842957, 0.800000011920929]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"my_tfhub_cache\"\n",
    "model= tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                   trainable=True, dtype=tf.string, input_shape=[]),\n",
    "    tf.keras.layers.Reshape(target_shape=(1, 512)),  # Ajustar la forma de entrada\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"nadam\",\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = model.fit(train_messages, train_labels_one_hot, batch_size=32, epochs=7, validation_data=(val_messages, val_labels_one_hot))\n",
    "\n",
    "print()\n",
    "print(\"Model Score: \", model.evaluate(test_messages, test_labels_one_hot, verbose=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo muestra un rendimiento en la tarea de clasificación binaria.\n",
    "La precisión en el conjunto de prueba se puede verificar con model.evaluate.\n",
    "El uso del Universal Sentence Encoder permite aprovechar la información semántica preentrenada y mejorar el rendimiento en tareas específicas.\n",
    "\n",
    "1. Rendimiento durante el Entrenamiento:\n",
    "\n",
    "Precisión (Accuracy): La precisión del modelo en el conjunto de entrenamiento aumenta progresivamente, alcanzando un valor de aproximadamente 98.95% al final del entrenamiento.\n",
    "Pérdida (Loss): La función de pérdida disminuye, indicando que el modelo está aprendiendo y mejorando su capacidad para hacer predicciones precisas.\n",
    "\n",
    "2. Evaluación en el Conjunto de Validación:\n",
    "\n",
    "La precisión en el conjunto de validación muestra variabilidad, alcanzando un máximo de aproximadamente 91.74% en la tercera época. Posteriormente, la precisión disminuye en las últimas épocas.\n",
    "La variabilidad y la disminución de la precisión podrían indicar cierta sensibilidad a overfitting o la necesidad de ajustar hiperparámetros.\n",
    "\n",
    "3. Model Score en el Conjunto de Prueba:\n",
    "\n",
    "El modelo logra una precisión del 80% en el conjunto de prueba según el model.evaluate.\n",
    "La pérdida en el conjunto de prueba es de aproximadamente 0.419.\n",
    "Consideraciones:\n",
    "\n",
    "El rendimiento del modelo en el conjunto de prueba es razonable, pero podría haber espacio para mejorar.\n",
    "La disminución en la precisión después de las primeras épocas en el conjunto de validación podría indicar overfitting. Se podría considerar la incorporación de técnicas de regularización o ajuste de la tasa de aprendizaje.\n",
    "Es importante considerar el equilibrio entre la precisión en el conjunto de entrenamiento y la capacidad del modelo para generalizar a nuevos datos.\n",
    "Se podría explorar la posibilidad de ajustar la arquitectura del modelo, experimentar con diferentes tasas de aprendizaje o aplicar técnicas de regularización para mejorar aún más el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre del Modelo: Universal Sentence Encoder GRU\n",
    "\n",
    "Descripción: Este modelo utiliza el Universal Sentence Encoder (versión 4) como una capa de entrada para la representación semántica de oraciones. Luego, se agrega una capa de Reshape para ajustar la forma de entrada antes de pasar a una capa GRU (Gated Recurrent Unit) con 128 unidades. Finalmente, hay una capa densa con función de activación sigmoide para la clasificación binaria.\n",
    "\n",
    "Configuración Adicional:\n",
    "\n",
    "Optimizador: Adam con tasa de aprendizaje inicial de 0.01, decaimiento de 0.004, y otros parámetros configurados.\n",
    "Función de Pérdida: Binary Crossentropy.\n",
    "Métrica de Evaluación: Precisión (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "126/126 [==============================] - 297s 2s/step - loss: 0.2982 - accuracy: 0.8734 - val_loss: 0.5263 - val_accuracy: 0.5261\n",
      "Epoch 2/7\n",
      "126/126 [==============================] - 264s 2s/step - loss: 0.1360 - accuracy: 0.9593 - val_loss: 0.6439 - val_accuracy: 0.7429\n",
      "Epoch 3/7\n",
      "126/126 [==============================] - 282s 2s/step - loss: 0.0577 - accuracy: 0.9868 - val_loss: 1.0636 - val_accuracy: 0.6836\n",
      "Epoch 4/7\n",
      "126/126 [==============================] - 281s 2s/step - loss: 0.0388 - accuracy: 0.9903 - val_loss: 1.0702 - val_accuracy: 0.6737\n",
      "Epoch 5/7\n",
      "126/126 [==============================] - 283s 2s/step - loss: 0.0343 - accuracy: 0.9908 - val_loss: 2.3124 - val_accuracy: 0.5240\n",
      "Epoch 6/7\n",
      "126/126 [==============================] - 290s 2s/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 1.6381 - val_accuracy: 0.6257\n",
      "Epoch 7/7\n",
      "126/126 [==============================] - 299s 2s/step - loss: 0.0298 - accuracy: 0.9918 - val_loss: 2.2865 - val_accuracy: 0.5685\n",
      "\n",
      "Model Score:  [0.5967699289321899, 0.800000011920929]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"my_tfhub_cache\"\n",
    "model11= tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                   trainable=True, dtype=tf.string, input_shape=[]),\n",
    "    tf.keras.layers.Reshape(target_shape=(1, 512)),  # Ajustar la forma de entrada\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "optimizador = tf.keras.optimizers.Adam(learning_rate=0.01,\n",
    "                                       decay=0.004,\n",
    "                                       beta_1=0.9,\n",
    "                                       beta_2=0.999,\n",
    "                                       epsilon=1e-07)\n",
    "model11.compile(loss='binary_crossentropy', optimizer=optimizador,\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history11 = model11.fit(train_messages, train_labels_one_hot, batch_size=32, epochs=7, validation_data=(val_messages, val_labels_one_hot))\n",
    "\n",
    "print()\n",
    "print(\"Model Score: \", model11.evaluate(test_messages, test_labels_one_hot, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados del Entrenamiento:\n",
    "\n",
    "Precisión en Entrenamiento: Aumenta progresivamente y alcanza alrededor del 99.18% al final del entrenamiento.\n",
    "Pérdida en Entrenamiento: Disminuye, indicando aprendizaje.\n",
    "Precisión en Validación: Alcanza alrededor del 68.36% en la tercera época pero muestra variabilidad y disminución en las últimas épocas.\n",
    "Pérdida en Validación: Aumenta, indicando posible overfitting.\n",
    "Model Score en el Conjunto de Prueba:\n",
    "\n",
    "Precisión en Prueba: 80%\n",
    "Pérdida en Prueba: 0.597\n",
    "Análisis de Resultados:\n",
    "\n",
    "La precisión en entrenamiento es alta, pero hay signos de overfitting, ya que la precisión en validación varía y disminuye en las últimas épocas.\n",
    "La pérdida en validación aumenta, lo que sugiere que el modelo podría estar memorizando en lugar de generalizar.\n",
    "La precisión en el conjunto de prueba es razonable, pero podría haber espacio para mejorar.\n",
    "Se podría explorar la posibilidad de ajustar la arquitectura del modelo, experimentar con diferentes tasas de aprendizaje o aplicar técnicas de regularización para mejorar aún más el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar lo modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.save('gru_model.h5', overwrite=True)\n",
    "model.save('model.h5', overwrite=True)\n",
    "model11.save('model11.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = tf.keras.models.load_model('gru_model.h5')\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "model11 = tf.keras.models.load_model('model11.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5968 - accuracy: 0.8000\n",
      "\n",
      " Resultados de la evaluación del modelo_ [0.5967699289321899, 0.800000011920929]\n"
     ]
    }
   ],
   "source": [
    "# Tamaño del lote\n",
    "lote = 32\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "evaluacion11 = model11.evaluate(test_messages, test_labels_one_hot,\n",
    "                                batch_size=lote,\n",
    "                                verbose=\"auto\")\n",
    "\n",
    "# Imprimir los resultados de la evaluación\n",
    "print('\\n Resultados de la evaluación del modelo_', evaluacion11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediccion del Modelo: Universal Sentence Encoder GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicciones sobre datos test\n",
    "# Convierte los datos de entrada en una lista de cadenas\n",
    "test_messages = [str(message) for message in test_messages]\n",
    "\n",
    "# Predicciones sobre datos test\n",
    "predicciones = model11.predict(test_messages)\n",
    "\n",
    "predicciones_lista = []\n",
    "for i in predicciones:\n",
    "    predicciones_lista.append(np.argmax(i))\n",
    "predicciones_lista = np.asarray(predicciones_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 5ms/step\n",
      "Confusion Matrix:\n",
      " [[ 84  42]\n",
      " [ 84 420]]\n",
      "F1 Score: 0.8099378881987578\n",
      "Fbeta Score: 0.8099378881987578\n",
      "Precision: 0.8272727272727274\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def calculate_metrics(model, messages, labels, beta=1):\n",
    "    # Convertir mensajes a una lista de cadenas\n",
    "    messages = [str(message) for message in messages]\n",
    "    \n",
    "    # Obtener predicciones del modelo\n",
    "    predictions = model.predict(messages)\n",
    "    \n",
    "    # Convertir predicciones a etiquetas binarias\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Convertir etiquetas verdaderas a etiquetas binarias si es necesario\n",
    "    true_labels = np.argmax(labels, axis=1) if len(labels.shape) > 1 else labels\n",
    "    \n",
    "    # Calcular matriz de confusión\n",
    "    confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    # Calcular F1 Score\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    # Calcular Fbeta Score (con beta específico, por defecto beta=1 para F1 Score)\n",
    "    fbeta = fbeta_score(true_labels, predicted_labels, beta=beta, average='weighted')\n",
    "    \n",
    "    # Calcular Precision y Recall\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    return confusion_mat, f1, fbeta, precision, recall\n",
    "\n",
    "conf_mat, f1_scr, fbeta_scr, precision_scr, recall_scr = calculate_metrics(model11, test_messages, test_encoded_labels)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "print(\"F1 Score:\", f1_scr)\n",
    "print(\"Fbeta Score:\", fbeta_scr)\n",
    "print(\"Precision:\", precision_scr)\n",
    "print(\"Recall:\", recall_scr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediccion del Modelo con Transfer Learning (Universal Sentence Encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicciones sobre datos test\n",
    "# Convierte los datos de entrada en una lista de cadenas\n",
    "test_messages = [str(message) for message in test_messages]\n",
    "\n",
    "# Predicciones sobre datos test\n",
    "predicciones = model.predict(test_messages)\n",
    "\n",
    "predicciones_lista = []\n",
    "for i in predicciones:\n",
    "    predicciones_lista.append(np.argmax(i))\n",
    "predicciones_lista = np.asarray(predicciones_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 6ms/step\n",
      "Confusion Matrix:\n",
      " [[ 84  42]\n",
      " [ 84 420]]\n",
      "F1 Score: 0.8099378881987578\n",
      "Fbeta Score: 0.8099378881987578\n",
      "Precision: 0.8272727272727274\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "conf_mat, f1_scr, fbeta_scr, precision_scr, recall_scr = calculate_metrics(model, test_messages, test_encoded_labels)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "print(\"F1 Score:\", f1_scr)\n",
    "print(\"Fbeta Score:\", fbeta_scr)\n",
    "print(\"Precision:\", precision_scr)\n",
    "print(\"Recall:\", recall_scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo Benchmark\n",
    "\n",
    "Modelo Benchmark muestra los resultados de un estudio sobre el uso de diferentes modelos para detectar mentiras. El estudio se dividió en dos tareas: detectar mentiras reales y detectar mentiras sospechosas.\n",
    "\n",
    "En la tarea de detectar mentiras reales, el modelo más eficaz fue el modelo neural que integraba mensajes anteriores y dinámicas de poder. Este modelo obtuvo una puntuación F1 de 56,1, que es comparable a la puntuación F1 de un humano.\n",
    "\n",
    "En la tarea de detectar mentiras sospechosas, el modelo más eficaz fue el modelo de bag of words. Este modelo obtuvo una puntuación F1 de 51,6, que es ligeramente superior a la puntuación F1 del modelo de mayoría de clases.\n",
    "\n",
    "En general, los resultados del estudio sugieren que los modelos neurales son más eficaces para detectar mentiras reales que los modelos basados en características lingüísticas. Sin embargo, los modelos basados en características lingüísticas son más eficaces para detectar mentiras sospechosas.\n",
    "\n",
    "Aquí hay una interpretación más detallada de los resultados:\n",
    "\n",
    "Tarea de detectar mentiras reales\n",
    "\n",
    "El modelo aleatorio obtuvo una puntuación F1 de 39,8. Esto significa que, en promedio, el modelo aleatorio acertó en el 39,8% de los casos.\n",
    "El modelo de mayoría de clases obtuvo una puntuación F1 de 47,8. Esto significa que, en promedio, el modelo de mayoría de clases acertó en el 47,8% de los casos.\n",
    "El modelo de harbingers obtuvo una puntuación F1 de 52,8. Esto significa que, en promedio, el modelo de harbingers acertó en el 52,8% de los casos.\n",
    "El modelo de bag of words obtuvo una puntuación F1 de 54,3. Esto significa que, en promedio, el modelo de bag of words acertó en el 54,3% de los casos.\n",
    "El modelo de LSTM obtuvo una puntuación F1 de 53,8. Esto significa que, en promedio, el modelo de LSTM acertó en el 53,8% de los casos.\n",
    "El modelo de contexto LSTM obtuvo una puntuación F1 de 55,8. Esto significa que, en promedio, el modelo de contexto LSTM acertó en el 55,8% de los casos.\n",
    "El modelo de contexto LSTM + BERT obtuvo una puntuación F1 de 56,1. Esto significa que, en promedio, el modelo de contexto LSTM + BERT acertó en el 56,1% de los casos.\n",
    "Como se puede ver, el modelo de contexto LSTM + BERT obtuvo la puntuación F1 más alta, lo que lo convierte en el modelo más eficaz para detectar mentiras reales. Este modelo integra mensajes anteriores y dinámicas de poder, lo que le permite identificar patrones que los otros modelos no pueden ver.\n",
    "\n",
    "Tarea de detectar mentiras sospechosas\n",
    "\n",
    "El modelo aleatorio obtuvo una puntuación F1 de 38,3. Esto significa que, en promedio, el modelo aleatorio acertó en el 38,3% de los casos.\n",
    "El modelo de mayoría de clases obtuvo una puntuación F1 de 48,3. Esto significa que, en promedio, el modelo de mayoría de clases acertó en el 48,3% de los casos.\n",
    "El modelo de harbingers obtuvo una puntuación F1 de 45,9. Esto significa que, en promedio, el modelo de harbingers acertó en el 45,9% de los casos.\n",
    "El modelo de bag of words obtuvo una puntuación F1 de 51,5. Esto significa que, en promedio, el modelo de bag of words acertó en el 51,5% de los casos.\n",
    "El modelo de LSTM obtuvo una puntuación F1 de 53,8. Esto significa que, en promedio, el modelo de LSTM acertó en el 53,8% de los casos.\n",
    "Como se puede ver, el modelo de bag of words obtuvo la puntuación F1 más alta, lo que lo convierte en el modelo más eficaz para detectar mentiras sospechosas. Este modelo utiliza características lingüísticas para identificar patrones que pueden indicar que una persona está mintiendo.\n",
    "\n",
    "En general, los resultados del estudio sugieren que los modelos neurales son más eficaces para detectar mentiras reales que los modelos basados en características lingüísticas. Sin embargo, los modelos basados en características lingüísticas son más eficaces para detectar mentiras sospechosas.\n",
    "\n",
    "#### Comparacion de los resultados con el modelo:\n",
    "\n",
    "Los resultados de los dos modelos que se presentan son muy similares a los resultados del estudio que se muestra en la imagen. En ambos casos, los modelos neurales obtienen una puntuación F1 más alta en la tarea de detectar mentiras reales que en la tarea de detectar mentiras sospechosas.\n",
    "\n",
    "En particular, el modelo Universal Sentence Encoder GRU obtuvo una puntuación F1 de 0,8099 en ambas tareas. Este modelo utiliza una arquitectura GRU para procesar el texto, lo que le permite aprender patrones a nivel de palabras y oraciones.\n",
    "\n",
    "El modelo Universal Sentence Encoder con Transfer Learning también obtuvo una puntuación F1 de 0,8099 en ambas tareas. Este modelo utiliza un modelo preentrenado de Universal Sentence Encoder para aprender las características del lenguaje.\n",
    "\n",
    "En general, los resultados de estos dos modelos sugieren que los modelos neurales son una buena opción para detectar mentiras. Estos modelos son capaces de aprender patrones complejos en el lenguaje que pueden ayudar a identificar a las personas que están mintiendo.\n",
    "\n",
    "Sin embargo, es importante tener en cuenta que los resultados de estos estudios se basan en conjuntos de datos específicos. Es posible que los resultados sean diferentes si se utilizan otros conjuntos de datos. Además, los modelos neurales pueden ser sensibles a los sesgos en los datos de entrenamiento.\n",
    "\n",
    "A continuación se presenta un análisis más detallado de los resultados de los dos modelos:\n",
    "\n",
    "Modelo Universal Sentence Encoder GRU\n",
    "\n",
    "Tarea de detectar mentiras reales:\n",
    "Precisión: 0,8272727272727274\n",
    "Recall: 0,8\n",
    "F1 Score: 0,8099378881987578\n",
    "El modelo Universal Sentence Encoder GRU obtuvo una precisión de 0,8272727272727274 en la tarea de detectar mentiras reales. Esto significa que el modelo acertó en el 82,72% de los casos en que una persona estaba mintiendo. El modelo también obtuvo un recall de 0,8, lo que significa que detectó el 80% de las mentiras reales.\n",
    "\n",
    "En general, el modelo Universal Sentence Encoder GRU es capaz de detectar mentiras reales con un alto grado de precisión y recall.\n",
    "\n",
    "Modelo Universal Sentence Encoder con Transfer Learning\n",
    "\n",
    "Tarea de detectar mentiras reales:\n",
    "Precisión: 0,8272727272727274\n",
    "Recall: 0,8\n",
    "F1 Score: 0,8099378881987578\n",
    "El modelo Universal Sentence Encoder con Transfer Learning obtuvo los mismos resultados que el modelo Universal Sentence Encoder GRU en la tarea de detectar mentiras reales. Esto sugiere que el uso de transferencia de aprendizaje no mejora el rendimiento del modelo en esta tarea.\n",
    "\n",
    "En general, los resultados de estos dos modelos sugieren que los modelos neurales son una buena opción para detectar mentiras. Estos modelos son capaces de aprender patrones complejos en el lenguaje que pueden ayudar a identificar a las personas que están mintiendo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
