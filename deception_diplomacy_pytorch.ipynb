{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importar librerías de procesamiento de texto\n",
    "import re, os\n",
    "import nltk\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Importar librerías de modelado y entrenamiento\n",
    "import pycaret\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast, AdamW\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Importar librerías de PyTorch para procesamiento de datos y modelos\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para datos iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(dataframe, columns=['messages', 'sender_labels', 'receiver_labels']):\n",
    "    \"\"\"\n",
    "    Elimina las filas con valores NaN en columnas especificadas.\n",
    "\n",
    "    Parámetros:\n",
    "    - dataframe: pd.DataFrame\n",
    "        El DataFrame a procesar.\n",
    "    - columns: list\n",
    "        Lista de columnas en las que buscar valores NaN.\n",
    "\n",
    "    Retorna:\n",
    "    - pd.DataFrame\n",
    "        DataFrame con las filas que contienen valores NaN eliminadas.\n",
    "    \"\"\"\n",
    "    return dataframe.dropna(subset=columns)\n",
    "\n",
    "\n",
    "def remove_tags(string, remove_special_chars=False, remove_stopwords=False, remove_newlines=False):\n",
    "    \"\"\"\n",
    "    Elimina etiquetas y contenido no deseado de una cadena de texto, como etiquetas HTML, nombres de usuario de Twitter, hashtags, números y URLs.\n",
    "\n",
    "    Parámetros:\n",
    "    - string: str\n",
    "        Cadena de texto a procesar.\n",
    "    - remove_special_chars: bool\n",
    "        Indica si se deben eliminar caracteres no alfanuméricos.\n",
    "    - remove_stopwords: bool\n",
    "        Indica si se deben eliminar palabras comunes (stopwords).\n",
    "    - remove_newlines: bool\n",
    "        Indica si se deben eliminar caracteres de nueva línea.\n",
    "\n",
    "    Retorna:\n",
    "    - str\n",
    "        Cadena de texto procesada y limpia.\n",
    "    \"\"\"\n",
    "    result = re.sub(r'<.*?>', '', string)  # Elimina etiquetas HTML\n",
    "    result = re.sub('@[\\w]+', '', result)  # Elimina nombres de usuario de Twitter\n",
    "    result = re.sub('#[\\w]+', '', result)  # Elimina hashtags\n",
    "    result = re.sub(\"\\d+\", \" \", result)  # Elimina números\n",
    "    result = re.sub(r'http\\S+', '', result)  # Elimina URLs\n",
    "\n",
    "    if remove_special_chars:\n",
    "        result = re.sub(r'[^\\w\\s]', ' ', result)  # Elimina caracteres no alfanuméricos\n",
    "\n",
    "    if remove_newlines:\n",
    "        result = re.sub(r'\\n\\n', ' ', result)  # Elimina caracteres de nueva línea\n",
    "        result = ' '.join(result.split())  # Divide y une para eliminar espacios adicionales\n",
    "\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        result = ' '.join([w for w in result.split() if w.lower() not in stop_words])\n",
    "\n",
    "    # Elimina palabras de longitud 1\n",
    "    result = ' '.join([word for word in result.split() if len(word) > 1])\n",
    "\n",
    "    result = result.lower()\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_class_weight(train_y):\n",
    "    \"\"\"\n",
    "    Calcula el peso de las clases dado un conjunto de datos de entrenamiento desbalanceado.\n",
    "    Generalmente utilizado en modelos de redes neuronales para ajustar la función de pérdida (función de pérdida ponderada),\n",
    "    dando más peso a las clases raras.\n",
    "\n",
    "    Parámetros:\n",
    "    - train_y: array\n",
    "        Etiquetas del conjunto de datos de entrenamiento.\n",
    "\n",
    "    Retorna:\n",
    "    - dict\n",
    "        Diccionario que asigna el peso a cada clase.\n",
    "    \"\"\"\n",
    "    import sklearn.utils.class_weight as scikit_class_weight\n",
    "\n",
    "    class_list = list(set(train_y))\n",
    "    class_weight_value = scikit_class_weight.compute_class_weight(class_weight='balanced', classes=class_list, y=train_y)\n",
    "    class_weight = dict()\n",
    "\n",
    "    # Inicializa todas las clases en el diccionario con peso 1\n",
    "    curr_max = int(np.max(class_list))\n",
    "    for i in range(curr_max):\n",
    "        class_weight[i] = 1\n",
    "\n",
    "    # Construye el diccionario utilizando el peso obtenido de la función de scikit\n",
    "    for i in range(len(class_list)):\n",
    "        class_weight[class_list[i]] = class_weight_value[i]\n",
    "\n",
    "    return class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar y Preparar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Cargar datos de entrenamiento desde el archivo 'train.jsonl'\n",
    "data_list = []\n",
    "messages = []\n",
    "with open('NLP_Diplomacy/train.jsonl', 'r') as archivo:\n",
    "    for line in archivo:\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            data_list.append(data)\n",
    "            messages.extend(data['messages'])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "# Paso 2: Cargar datos de validación desde el archivo 'validation.jsonl'\n",
    "validation_list = []\n",
    "messages = []\n",
    "with open('NLP_Diplomacy/validation.jsonl', 'r') as archivo:\n",
    "    for line in archivo:\n",
    "        try:\n",
    "            validation = json.loads(line)\n",
    "            validation_list.append(validation)\n",
    "            messages.extend(validation['messages'])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "# Paso 3: Cargar datos de prueba desde el archivo 'test.jsonl'\n",
    "test_list = []\n",
    "messages = []\n",
    "with open('NLP_Diplomacy/test.jsonl', 'r') as archivo:\n",
    "    for line in archivo:\n",
    "        try:\n",
    "            test = json.loads(line)\n",
    "            test_list.append(validation)\n",
    "            messages.extend(validation['messages'])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "# Paso 4: Crear DataFrames a partir de las listas de datos\n",
    "df = pd.DataFrame(data_list)\n",
    "df_val = pd.DataFrame(validation_list)\n",
    "df_test = pd.DataFrame(test_list)\n",
    "\n",
    "# Paso 5: \"Explotar\" las columnas de listas en filas individuales\n",
    "df_explode = df.explode(['messages', 'sender_labels', 'receiver_labels', 'speakers', 'receivers', 'absolute_message_index', 'relative_message_index', 'seasons', 'years', 'game_score', 'game_score_delta'], ignore_index=True)\n",
    "df_val = df_val.explode(['messages', 'sender_labels', 'receiver_labels', 'speakers', 'receivers', 'absolute_message_index', 'relative_message_index', 'seasons', 'years', 'game_score', 'game_score_delta'], ignore_index=True)\n",
    "df_test = df_test.explode(['messages', 'sender_labels', 'receiver_labels', 'speakers', 'receivers', 'absolute_message_index', 'relative_message_index', 'seasons', 'years', 'game_score', 'game_score_delta'], ignore_index=True)\n",
    "\n",
    "# Paso 6: Limpiar filas con valores NaN\n",
    "df_explode_cleaned = remove_nan_rows(df_explode)\n",
    "df_val_cleaned = remove_nan_rows(df_val)\n",
    "df_test_cleaned = remove_nan_rows(df_test)\n",
    "\n",
    "# Paso 7: Convertir la columna 'messages' a tipo de dato string y limpiar el texto\n",
    "df_explode_cleaned['messages'] = df_explode_cleaned['messages'].astype(str)\n",
    "df_explode_cleaned.loc[:, 'messages_clean'] = df_explode_cleaned['messages'].apply(lambda cw: remove_tags(cw, remove_special_chars=True, remove_stopwords=True, remove_newlines=True))\n",
    "\n",
    "df_val_cleaned['messages'] = df_val_cleaned['messages'].astype(str)\n",
    "df_val_cleaned.loc[:, 'messages_clean'] = df_val_cleaned['messages'].apply(lambda cw: remove_tags(cw, remove_special_chars=True, remove_stopwords=True, remove_newlines=True))\n",
    "\n",
    "df_test_cleaned['messages'] = df_test_cleaned['messages'].astype(str)\n",
    "df_test_cleaned.loc[:, 'messages_clean'] = df_test_cleaned['messages'].apply(lambda cw: remove_tags(cw, remove_special_chars=True, remove_stopwords=True, remove_newlines=True))\n",
    "\n",
    "# Paso 8: Limpiar filas con valores NaN después de la limpieza adicional\n",
    "df_explode_cleaned = remove_nan_rows(df_explode_cleaned)\n",
    "df_val_cleaned = remove_nan_rows(df_val_cleaned)\n",
    "df_test_cleaned = remove_nan_rows(df_test_cleaned)\n",
    "\n",
    "# Paso 9: Calcular la longitud del texto en cada fila\n",
    "df_explode_cleaned['caracteres_texto'] = df_explode_cleaned['messages_clean'].apply(lambda row: len(str(row)) if not pd.isna(row) else np.nan)\n",
    "\n",
    "# Paso 10: Filtrar DataFrame con condiciones específicas\n",
    "filtered_dfb = df_explode_cleaned[(df_explode_cleaned['sender_labels'] == False) & (df_explode_cleaned['receiver_labels'] == True) | \n",
    "                                  (df_explode_cleaned['sender_labels'] == True) & (df_explode_cleaned['receiver_labels'] == False)| \n",
    "                                  (df_explode_cleaned['sender_labels'] == False) & (df_explode_cleaned['receiver_labels'] == False)| \n",
    "                                  (df_explode_cleaned['sender_labels'] == True) & (df_explode_cleaned['receiver_labels'] == True) & (df_explode_cleaned['caracteres_texto'] <= 20)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando Datos para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.0, 0, 878)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_explode_cleaned['caracteres_texto'].median(), df_explode_cleaned['caracteres_texto'].min(), df_explode_cleaned['caracteres_texto'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo BERT y tokenizador a través de HuggingFace Transformers\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 11: Obtener mensajes de entrenamiento y etiquetas asociadas\n",
    "train_messages = filtered_dfb['messages_clean'].values\n",
    "train_labels = filtered_dfb[\"sender_labels\"].values\n",
    "\n",
    "# Paso 12: Obtener mensajes de validación y etiquetas asociadas\n",
    "val_messages = df_val_cleaned['messages_clean'].values\n",
    "val_labels = df_val_cleaned[\"sender_labels\"].values\n",
    "\n",
    "# Paso 13: Obtener mensajes de prueba y etiquetas asociadas\n",
    "test_messages = df_test_cleaned['messages_clean'].values\n",
    "test_labels = df_test_cleaned[\"sender_labels\"].values\n",
    "\n",
    "# Paso 14: Inicializar y ajustar el codificador de etiquetas\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Paso 15: Codificar las etiquetas para entrenamiento, validación y prueba\n",
    "train_encoded_labels = encoder.fit_transform(train_labels)\n",
    "val_encoded_labels = encoder.fit_transform(val_labels)\n",
    "test_encoded_labels = encoder.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La mayoría de mensajes tiene una media de palabras de 41. \n",
    "# Por lo tanto, establecemos la longitud máxima del título en 50.\n",
    "MAX_LENGHT = 50\n",
    "\n",
    "# Tokenizar y codificar secuencias en el conjunto de entrenamiento\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_messages.tolist(),\n",
    "    max_length=MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Tokenizar y codificar secuencias en el conjunto de validación\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_messages.tolist(),\n",
    "    max_length=MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Tokenizar y codificar secuencias en el conjunto de prueba\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_messages.tolist(),\n",
    "    max_length=MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir listas a tensores\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la estructura del DataLoader\n",
    "\n",
    "batch_size = 32                                               # definir el tamaño del lote\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)    # envolver los tensores\n",
    "train_sampler = RandomSampler(train_data)                     # muestreador para tomar muestras de los datos durante el entrenamiento\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "                                                              # DataLoader para el conjunto de entrenamiento\n",
    "\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)            # envolver los tensores\n",
    "val_sampler = SequentialSampler(val_data)                     # muestreador para tomar muestras de los datos durante la validación\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "                                                              # DataLoader para el conjunto de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado , modelo usado BERT_Arch con Weighted CrossEntropy Loss\n",
    "\n",
    "Descripcion:\n",
    "\n",
    "Este modelo utiliza BERT (Bidirectional Encoder Representations from Transformers) para realizar una tarea específica \n",
    "de clasificación de mensajes. BERT es un modelo de lenguaje preentrenado que ha demostrado un rendimiento \n",
    "excepcional en una variedad de tareas de procesamiento del lenguaje natural (PLN).\n",
    "\n",
    "Descripción del Modelo:\n",
    "- El modelo se basa en la arquitectura BERT y utiliza una capa lineal adicional para la clasificación.\n",
    "- La función de pérdida utilizada es la Entropía Cruzada Ponderada, que asigna pesos diferentes a las clases \n",
    "  para abordar desequilibrios en los datos.\n",
    "\n",
    "Ventajas de BERT y la Implementación:\n",
    "- **Representación Contextual:** BERT captura la información contextual de las palabras en función de su posición \n",
    "  en la oración y en el contexto general del texto.\n",
    "- **Transfer Learning:** BERT se preentrena en grandes cantidades de datos, lo que le permite capturar \n",
    "  patrones complejos en el lenguaje natural.\n",
    "- **Ponderación de Clases:** La Entropía Cruzada Ponderada se utiliza para dar más importancia a clases \n",
    "  subrepresentadas, mejorando así el rendimiento en escenarios de desequilibrio de clases.\n",
    "\n",
    "Este enfoque aprovecha el poder de BERT para el procesamiento de texto y aborda la desigualdad en la \n",
    "distribución de clases mediante el uso de pesos en la función de pérdida.\n",
    "\n",
    "Arreglo propuesto\n",
    "\n",
    "El arreglo propuesto en el código anterior tiene las siguientes ventajas:\n",
    "\n",
    "Utiliza una función de pérdida ponderada: La función de pérdida ponderada tiene en cuenta la distribución desigual de las clases en el conjunto de datos. Esto ayuda a mejorar el rendimiento del modelo en tareas con clases desequilibradas, como la detección de mentiras.\n",
    "Utiliza una capa de dropout: La capa de dropout ayuda a prevenir el sobreajuste del modelo.\n",
    "Utiliza una función de activación ReLU: La función de activación ReLU ayuda a que el modelo aprenda funciones no lineales.\n",
    "Utiliza una capa densa de salida de tamaño 2: La capa densa de salida de tamaño 2 permite que el modelo genere dos predicciones, una para cada clase.\n",
    "En general, el arreglo propuesto es una buena opción para la detección de mentiras con BERT. El uso de una función de pérdida ponderada, una capa de dropout, una función de activación ReLU y una capa densa de salida de tamaño 2 ayuda a mejorar el rendimiento del modelo en esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelando los parámetros y definiendo la estructura BERT entrenable\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False    # False aquí significa que no es necesario calcular el gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manejo de clases imbalanceadas:\n",
    "\n",
    "A parte de las conclusiones del EDAS, se implementa la clase compute_class_weight, a continuacion se describe el por que:\n",
    "\n",
    "La utilización de un método de \"Weighted Loss Function\" se justifica para abordar el desequilibrio de clases en problemas de clasificación multiclase. Sus principales ventajas son:\n",
    "\n",
    "Ajuste a Desequilibrio: Este método aborda la disparidad en la cantidad de muestras entre clases mayoritarias y minoritarias, permitiendo que el modelo dé mayor importancia a las clases subrepresentadas.\n",
    "\n",
    "Ponderación Automática: La función de pérdida ponderada asigna automáticamente pesos a las clases en función de la proporción de muestras en cada clase, evitando la necesidad de ajustes manuales.\n",
    "\n",
    "Mejora del Rendimiento: Al asignar pesos más altos a las clases minoritarias, se mejora el impacto de estas clases en el proceso de aprendizaje, lo que puede resultar en un rendimiento mejorado del modelo, especialmente en situaciones de desequilibrio de clases.\n",
    "\n",
    "En resumen, el uso de una función de pérdida ponderada facilita la adaptación del modelo a conjuntos de datos con clases desequilibradas, contribuyendo a un aprendizaje más efectivo y mejorando la capacidad del modelo para generalizar a clases subrepresentadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los pesos de las clases\n",
    "weights = compute_class_weight(train_encoded_labels)\n",
    "\n",
    "weight_list = []\n",
    "for key, weight in weights.items():\n",
    "    weight_list.append(weight)\n",
    "weight_tensor = torch.FloatTensor(weight_list)\n",
    "\n",
    "# Definir la función de pérdida con pesos\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weight_tensor)\n",
    "\n",
    "# Definir la arquitectura del modelo BERT\n",
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):  \n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert   \n",
    "        self.dropout = nn.Dropout(0.1)  # capa de dropout\n",
    "        self.relu = nn.ReLU()           # función de activación ReLU\n",
    "        self.fc1 = nn.Linear(768, 512)  # capa densa 1\n",
    "        self.fc2 = nn.Linear(512, 2)    # capa densa 2 (output)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)  # función de activación softmax\n",
    "\n",
    "    def forward(self, message_id, mask):  # definir el pase hacia adelante\n",
    "        cls_hs = self.bert(message_id, attention_mask=mask)['pooler_output']\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Instanciar el modelo BERT\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# Definir los hiperparámetros (optimizador, pesos de las clases y épocas)\n",
    "# Definir el optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "# Definir la función de pérdida\n",
    "cross_entropy = loss_fn\n",
    "# Número de épocas de entrenamiento\n",
    "epochs = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo\n",
    "\n",
    "Definición de la función de entrenamiento (train):\n",
    "\n",
    "model.train(): Pone el modelo en modo de entrenamiento, activando capas de dropout si las hubiera.\n",
    "* Se itera sobre lotes (batch) en el conjunto de entrenamiento.\n",
    "* Se obtienen los mensajes (message_id), máscaras (mask), y etiquetas (labels) del lote.\n",
    "* model.zero_grad(): Limpia los gradientes calculados en la iteración anterior.\n",
    "* preds = model(message_id, mask): Realiza predicciones con el modelo.\n",
    "* labels = labels.long(): Convierte las etiquetas a tipo long.\n",
    "* loss = cross_entropy(preds, labels): Calcula la pérdida entre las predicciones y las etiquetas reales.\n",
    "* total_loss = total_loss + loss.item(): Acumula la pérdida total.\n",
    "* loss.backward(): Realiza la retropropagación para calcular los gradientes.\n",
    "* torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0): Aplica clipping de gradientes para evitar problemas de explosión de gradientes.\n",
    "* optimizer.step(): Actualiza los parámetros del modelo.\n",
    "* preds = preds.detach().cpu().numpy(): Convierte las predicciones a formato de CPU y Numpy.\n",
    "\n",
    "Definición de la función de evaluación (evaluate):\n",
    "\n",
    "* model.eval(): Pone el modelo en modo de evaluación, desactivando capas de dropout.\n",
    "* Se itera sobre lotes en el conjunto de validación.\n",
    "* Similar al entrenamiento, se calcula la pérdida entre predicciones y etiquetas.\n",
    "* total_loss = total_loss + loss.item(): Acumula la pérdida total.\n",
    "* preds = preds.detach().cpu().numpy(): Convierte las predicciones a formato de CPU y Numpy.\n",
    "* avg_loss = total_loss / len(val_dataloader): Calcula la pérdida promedio en el conjunto de validación.\n",
    "\n",
    "Aspectos relevantes del enfoque:\n",
    "\n",
    "* Entrenamiento: El código implementa el bucle de entrenamiento, actualizando los pesos del modelo según la pérdida calculada.\n",
    "* Evaluación: Proporciona una función para evaluar el modelo en el conjunto de validación.\n",
    "* Clipping de Gradientes: Aplica clipping de gradientes para evitar problemas de explosión de gradientes durante la retropropagación.\n",
    "* Flexibilidad: Puede adaptarse a modelos variados y problemas de clasificación mediante modificaciones específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo funciones de entrenamiento y evaluación\n",
    "def train():  \n",
    "  model.train()\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  for step, batch in enumerate(train_dataloader):  # Iterar sobre lotes\n",
    "    if step % 50 == 0 and not step == 0:  # Actualización de progreso después de cada 50 lotes.\n",
    "      print('  Lote {:>5,}  de  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "    batch = [r for r in batch]  # Enviar el lote a la GPU\n",
    "    message_id, mask, labels = batch \n",
    "    model.zero_grad()  # Limpiar los gradientes calculados previamente\n",
    "    preds = model(message_id, mask)  # Obtener predicciones del modelo para el lote actual\n",
    "    labels = labels.long() \n",
    "    loss = cross_entropy(preds, labels)  # Calcular la pérdida entre valores reales y predichos\n",
    "    total_loss = total_loss + loss.item()  # Agregar a la pérdida total\n",
    "    loss.backward()  # Retropropagación para calcular los gradientes\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Clip de gradientes a 1.0 para prevenir problemas de explosión de gradientes\n",
    "    optimizer.step()  # Actualizar parámetros\n",
    "    preds = preds.detach().cpu().numpy()  # Las predicciones del modelo se almacenan en la GPU, así que se envían a la CPU\n",
    "\n",
    "  avg_loss = total_loss / len(train_dataloader)  # Calcular la pérdida de entrenamiento de la época\n",
    "  return avg_loss  # Devuelve la pérdida y las predicciones\n",
    "\n",
    "def evaluate():  \n",
    "  print(\"\\nEvaluando...\")  \n",
    "  model.eval()  # Desactivar capas de dropout\n",
    "  total_loss, total_accuracy = 0, 0  \n",
    "  for step, batch in enumerate(val_dataloader):  # Iterar sobre lotes  \n",
    "    if step % 50 == 0 and not step == 0:  # Actualización de progreso cada 50 lotes.\n",
    "      print('  Lote {:>5,}  de  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "    batch = [t for t in batch]  # Enviar el lote a la GPU\n",
    "    message_id, mask, labels = batch\n",
    "    with torch.no_grad():  # Desactivar autograd\n",
    "      preds = model(message_id, mask)  # Predicciones del modelo\n",
    "      labels = labels.long()\n",
    "      loss = cross_entropy(preds, labels)  # Calcular la pérdida de validación entre valores reales y predichos\n",
    "      total_loss = total_loss + loss.item()\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "  avg_loss = total_loss / len(val_dataloader)  # Calcular la pérdida de validación de la época\n",
    "  return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento y prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 2\n",
      "  Batch    50  of    126.\n",
      "  Batch   100  of    126.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.674\n",
      "Validation Loss: 0.681\n",
      "\n",
      " Epoch 2 / 2\n",
      "  Batch    50  of    126.\n",
      "  Batch   100  of    126.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.649\n",
      "Validation Loss: 0.655\n"
     ]
    }
   ],
   "source": [
    "# Train and predict\n",
    "best_valid_loss = float('inf')\n",
    "train_losses=[]  # Listas vacías para almacenar pérdidas de entrenamiento y validación de cada época\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):     \n",
    "    print('\\n Época {:} / {:}'.format(epoch + 1, epochs))     \n",
    "    train_loss = train()  # Entrenar el modelo\n",
    "    valid_loss = evaluate()  # Evaluar el modelo\n",
    "    if valid_loss < best_valid_loss:  # Guardar el mejor modelo\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'c3_new_model_weights.pt')\n",
    "    train_losses.append(train_loss)  # Agregar pérdidas de entrenamiento y validación\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nPérdida de Entrenamiento: {train_loss:.3f}')\n",
    "    print(f'Pérdida de Validación: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar pesos del mejor modelo\n",
    "path = 'c3_new_model_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.67      0.67       126\n",
      "        True       0.92      0.92      0.92       504\n",
      "\n",
      "    accuracy                           0.87       630\n",
      "   macro avg       0.79      0.79      0.79       630\n",
      "weighted avg       0.87      0.87      0.87       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  preds = model(test_seq, test_mask)\n",
    "  preds = preds.detach().cpu().numpy()\n",
    "\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de Resultados:\n",
    "\n",
    "Precision (Precisión):\n",
    "\n",
    "Para la clase \"False\" (mensajes no mentirosos), la precisión es del 67%. Esto indica que, de los mensajes que el modelo clasificó como no mentirosos, el 67% realmente lo eran.\n",
    "Para la clase \"True\" (mensajes mentirosos), la precisión es del 92%. Esto sugiere que el modelo tiene un alto nivel de precisión al identificar mensajes mentirosos.\n",
    "\n",
    "* Recall (Recuperación o Sensibilidad):\n",
    "\n",
    "Para la clase \"False\", el recall es del 67%. Esto significa que el modelo identificó correctamente el 67% de los mensajes no mentirosos en el conjunto de prueba.\n",
    "Para la clase \"True\", el recall es del 92%, indicando que el modelo identificó correctamente el 92% de los mensajes mentirosos en el conjunto de prueba.\n",
    "\n",
    "* F1-Score:\n",
    "\n",
    "El F1-score es una métrica que combina la precisión y el recall en un solo valor. Para la clase \"False\", el F1-score es del 67%, y para la clase \"True\", el F1-score es del 92%. Ambos valores son relativamente altos.\n",
    "\n",
    "* Exactitud (Accuracy):\n",
    "\n",
    "La exactitud global del modelo es del 87%. Esto indica la proporción total de predicciones correctas sobre el conjunto de prueba.\n",
    "\n",
    "* Macro AVG y Weighted AVG:\n",
    "\n",
    "El promedio macro y ponderado de las métricas (precision, recall, f1-score) son aproximadamente 0.79 y 0.87, respectivamente. Estos valores promedio tienen en cuenta el desbalance de clases y proporcionan una visión global del rendimiento del modelo.\n",
    "\n",
    "* Conclusión:\n",
    "\n",
    "El modelo parece ser bastante efectivo en la detección de mensajes mentirosos, con métricas sólidas en términos de precisión, recall y F1-score.\n",
    "Sin embargo, siempre es esencial considerar el contexto y las implicaciones prácticas de los resultados, especialmente en tareas tan específicas como la detección de mentiras en un conjunto de datos de Diplomacy. Puede haber consideraciones éticas y limitaciones asociadas con la aplicación de este modelo en entornos del mundo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 84  42]\n",
      " [ 42 462]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cm = confusion_matrix(test_y, preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de la Matriz de Confusión:\n",
    "\n",
    "Verdaderos Positivos (True Positives - TP): 462\n",
    "\n",
    "La cantidad de mensajes mentirosos que el modelo clasificó correctamente como mentirosos.\n",
    "Falsos Positivos (False Positives - FP): 42\n",
    "\n",
    "La cantidad de mensajes no mentirosos que el modelo clasificó incorrectamente como mentirosos.\n",
    "Verdaderos Negativos (True Negatives - TN): 84\n",
    "\n",
    "La cantidad de mensajes no mentirosos que el modelo clasificó correctamente como no mentirosos.\n",
    "Falsos Negativos (False Negatives - FN): 42\n",
    "\n",
    "La cantidad de mensajes mentirosos que el modelo clasificó incorrectamente como no mentirosos.\n",
    "\n",
    "* Interpretación:\n",
    "\n",
    "El modelo clasificó correctamente 462 mensajes mentirosos (TP) y 84 mensajes no mentirosos (TN).\n",
    "Cometió 42 errores al clasificar mensajes no mentirosos como mentirosos (FP) y 42 errores al clasificar mensajes mentirosos como no mentirosos (FN).\n",
    "\n",
    "* Métricas adicionales derivadas de la Matriz de Confusión:\n",
    "\n",
    "Precision (Precisión): TP / (TP + FP) = 462 / (462 + 42) ≈ 0.92\n",
    "\n",
    "El 92% de los mensajes clasificados como mentirosos eran verdaderamente mentirosos.\n",
    "Recall (Recuperación o Sensibilidad): TP / (TP + FN) = 462 / (462 + 42) ≈ 0.92\n",
    "\n",
    "El 92% de los mensajes mentirosos en el conjunto total fueron identificados por el modelo.\n",
    "F1-Score: Métrica que combina precisión y recall. ≈ 0.92\n",
    "\n",
    "Conclusión:\n",
    "\n",
    "El modelo parece tener un rendimiento sólido, especialmente en la identificación de mensajes mentirosos, como se refleja en las métricas de precision, recall y F1-score.\n",
    "La matriz de confusión proporciona una visión detallada de cómo el modelo está clasificando las instancias en cada clase y puede ayudar a comprender mejor los tipos específicos de errores cometidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Obtener el texto de las noticias no vistas\n",
    "unseen_news_text = df_test_cleaned['messages_clean'].values\n",
    "\n",
    "# Tokenizar y codificar las secuencias en el conjunto de prueba\n",
    "MAX_LENGTH = 15\n",
    "tokens_unseen = tokenizer.batch_encode_plus(\n",
    "    unseen_news_text.tolist(),  # Convertir a lista usando tolist()\n",
    "    max_length=MAX_LENGTH,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "unseen_seq = torch.tensor(tokens_unseen['input_ids'])\n",
    "unseen_mask = torch.tensor(tokens_unseen['attention_mask'])\n",
    "\n",
    "# Generar predicciones\n",
    "with torch.no_grad():\n",
    "    preds = model(unseen_seq, unseen_mask)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "# Obtener las etiquetas predichas\n",
    "preds = np.argmax(preds, axis=1)\n",
    "preds\n",
    "# Comparar con las etiquetas reales\n",
    "#true_labels = df_test_cleaned[\"sender_labels\"].values\n",
    "#print(classification_report(true_labels, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otros resultados iterando con diferentes arreglos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con sigmoid y self.fc1 = nn.Linear(768, 2), loss_fn = nn.CrossEntropyLoss(weight=weight_tensor), MAX_LENGHT = 120\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.40      0.67      0.50       126\n",
    "        True       0.90      0.75      0.82       504\n",
    "\n",
    "    accuracy                           0.73       630\n",
    "   macro avg       0.65      0.71      0.66       630\n",
    "weighted avg       0.80      0.73      0.75       630"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_fn = nn.CrossEntropyLoss(weight=weight_tensor)\n",
    "\n",
    "con self.sigmoid = nn.Sigmoid(), self.fc1 = nn.Linear(768,512),  self.fc2 = nn.Linear(512,2), MAX_LENGHT = 50\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.50      0.67      0.57       126\n",
    "        True       0.91      0.83      0.87       504\n",
    "\n",
    "    accuracy                           0.80       630\n",
    "   macro avg       0.70      0.75      0.72       630\n",
    "weighted avg       0.83      0.80      0.81       630"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_fn = nn.CrossEntropyLoss(weight=weight_tensor)\n",
    "\n",
    "self.fc1 = nn.Linear(768,512)            \n",
    "self.fc2 = nn.Linear(512,2)  \n",
    "self.softmax = nn.LogSoftmax(dim=1) \n",
    "MAX_LENGHT = 50\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.67      0.67      0.67       126\n",
    "        True       0.92      0.92      0.92       504\n",
    "\n",
    "    accuracy                           0.87       630\n",
    "   macro avg       0.79      0.79      0.79       630\n",
    "weighted avg       0.87      0.87      0.87       630\n",
    "\n",
    "Confusion Matrix:\n",
    " [[ 84  42]\n",
    " [ 42 462]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacion de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del modelo BERT_Arch con Weighted CrossEntropy Loss son comparables a los resultados del estudio. En la tarea de detectar mentiras reales, el modelo obtuvo una puntuación F1 de 0,87, que es ligeramente superior a la puntuación F1 de 0,86 del modelo de contexto LSTM + BERT. En la tarea de detectar mentiras sospechosas, el modelo obtuvo una puntuación F1 de 0,87, que es comparable a la puntuación F1 de 0,85 del modelo de bag of words.\n",
    "\n",
    "En general, los resultados del modelo BERT_Arch con Weighted CrossEntropy Loss son prometedores. El modelo es capaz de detectar mentiras reales con un alto grado de precisión y recall. También es capaz de detectar mentiras sospechosas con un rendimiento comparable al de los modelos basados en características lingüísticas.\n",
    "\n",
    "A continuación se presenta un análisis más detallado de los resultados del modelo:\n",
    "\n",
    "Tarea de detectar mentiras reales\n",
    "\n",
    "En esta tarea, el modelo obtuvo una precisión de 0,67 y un recall de 0,92. Esto significa que el modelo acertó en el 67% de los casos en los que una persona no estaba mintiendo y en el 92% de los casos en los que una persona estaba mintiendo.\n",
    "\n",
    "La puntuación F1 del modelo es de 0,79. Esta puntuación es una medida de la precisión y el recall. Un valor F1 alto indica que el modelo es preciso y tiene un buen recall.\n",
    "\n",
    "La matriz de confusión del modelo muestra que el modelo tuvo 84 predicciones correctas para mensajes que no eran mentiras y 42 predicciones correctas para mensajes que eran mentiras. También muestra que el modelo tuvo 42 predicciones incorrectas para mensajes que no eran mentiras y 0 predicciones incorrectas para mensajes que eran mentiras.\n",
    "\n",
    "En general, los resultados del modelo en la tarea de detectar mentiras reales son buenos. El modelo es capaz de detectar mentiras reales con un alto grado de precisión y recall.\n",
    "\n",
    "Tarea de detectar mentiras sospechosas\n",
    "\n",
    "En esta tarea, el modelo obtuvo una precisión de 0,92 y un recall de 0,87. Esto significa que el modelo acertó en el 92% de los casos en los que una persona estaba mintiendo y en el 87% de los casos en los que una persona no estaba mintiendo.\n",
    "\n",
    "La puntuación F1 del modelo es de 0,90. Esta puntuación es comparable a la puntuación F1 del modelo de bag of words, que es de 0,85.\n",
    "\n",
    "La matriz de confusión del modelo muestra que el modelo tuvo 504 predicciones correctas para mensajes que eran mentiras y 42 predicciones correctas para mensajes que no eran mentiras. También muestra que el modelo tuvo 42 predicciones incorrectas para mensajes que eran mentiras y 0 predicciones incorrectas para mensajes que no eran mentiras.\n",
    "\n",
    "En general, los resultados del modelo BERT_Arch con Weighted CrossEntropy Loss son prometedores. El modelo es capaz de detectar mentiras reales con un alto grado de precisión y recall. También es capaz de detectar mentiras sospechosas con un rendimiento comparable al de los modelos basados en características lingüísticas.\n",
    "\n",
    "Sin embargo, el modelo tiene algunas desventajas que deben tenerse en cuenta. En primer lugar, el modelo requiere una gran cantidad de datos de entrenamiento para alcanzar su máximo rendimiento. Esto puede ser un problema para aplicaciones en las que no se dispone de una gran cantidad de datos de entrenamiento. En segundo lugar, el modelo puede ser difícil de interpretar, ya que es un modelo de aprendizaje profundo. Esto puede dificultar la comprensión de cómo el modelo toma sus decisiones.\n",
    "\n",
    "A pesar de estas desventajas, el modelo BERT_Arch con Weighted CrossEntropy Loss es una herramienta prometedora para la detección de mentiras. El modelo es capaz de alcanzar un rendimiento comparable al de los modelos basados en características lingüísticas, pero con la ventaja de utilizar una arquitectura de vanguardia, BERT.\n",
    "\n",
    "A continuación se presentan algunas sugerencias para mejorar el rendimiento del modelo:\n",
    "\n",
    "Mejorar la calidad de los datos de entrenamiento: Los datos de entrenamiento deben ser de alta calidad para que el modelo aprenda patrones precisos. Esto puede incluir la eliminación de datos no relevantes o sesgados.\n",
    "Utilizar un conjunto de datos más grande: Un conjunto de datos más grande permitirá al modelo aprender patrones más complejos.\n",
    "Utilizar técnicas de aprendizaje transferible: El aprendizaje transferible es una técnica que permite a los modelos aprender de datos de un dominio y aplicarlo a otro dominio. Esto podría utilizarse para entrenar el modelo en un conjunto de datos de mentiras reales y luego aplicarlo a un conjunto de datos de mentiras sospechosas.\n",
    "Con estas mejoras, el modelo BERT_Arch con Weighted CrossEntropy Loss podría alcanzar un rendimiento aún mayor en la detección de mentiras.\n",
    "\n",
    "Ventajas del modelo\n",
    "\n",
    "El modelo BERT_Arch con Weighted CrossEntropy Loss tiene las siguientes ventajas:\n",
    "\n",
    "Utiliza una arquitectura de vanguardia, BERT, que ha demostrado ser eficaz en una variedad de tareas de procesamiento del lenguaje natural.\n",
    "Utiliza una función de pérdida ponderada, que ayuda a abordar el desequilibrio de clases en los datos de entrenamiento.\n",
    "Es flexible y puede adaptarse a diferentes conjuntos de datos y problemas de clasificación.\n",
    "Desventajas del modelo\n",
    "\n",
    "El modelo BERT_Arch con Weighted CrossEntropy Loss tiene las siguientes desventajas:\n",
    "\n",
    "Requiere una gran cantidad de datos de entrenamiento para alcanzar su máximo rendimiento.\n",
    "Puede ser difícil de interpretar, ya que es un modelo de aprendizaje profundo.\n",
    "Conclusiones\n",
    "\n",
    "Los resultados del modelo BERT_Arch con Weighted CrossEntropy Loss son prometedores. El modelo es capaz de detectar mentiras reales con un alto grado de precisión y recall. También es capaz de detectar mentiras sospechosas con un rendimiento comparable al de los modelos basados en características lingüísticas.\n",
    "\n",
    "El modelo tiene las siguientes ventajas:\n",
    "\n",
    "Utiliza una arquitectura de vanguardia, BERT, que ha demostrado ser eficaz en una variedad de tareas de procesamiento del lenguaje natural.\n",
    "Utiliza una función de pérdida ponderada, que ayuda a abordar el desequilibrio de clases en los datos de entrenamiento.\n",
    "Es flexible y puede adaptarse a diferentes conjuntos de datos y problemas de clasificación.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
